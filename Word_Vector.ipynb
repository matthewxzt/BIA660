{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Word Vector (a.k.a Word Embedding) </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Word2Vector\n",
    " - Vector representation of words (i.e. word vectors) learned using neural network\n",
    "   - e.g. \"apple\" : [0.35, -0.2, 0.4, ...], 'mongo':  [0.32, -0.18, 0.5, ...]\n",
    "   - Interesting properties of word vectors:\n",
    "    * **Words with similar semantics have close word vectors**\n",
    "    <img src=\"https://www.kdnuggets.com/images/cartoon-espresso-word2vec.jpg\" width=\"50%\">\n",
    "    https://www.kdnuggets.com/2017/04/cartoon-word2vec-espresso-cappuccino.html\n",
    "    * **Composition**: e.g. vector(\"woman\")+vector(\"king\")-vector('man') $\\approx$ vector(\"queen\")\n",
    " - Models:\n",
    "   - **CBOW** (Continuous Bag of Words): Predict a target word based on context\n",
    "     - e.g. the fox jumped over the lazy dog\n",
    "     - Assuming symmetric context with window size 3, this sentence can create training samples: \n",
    "       - ([-, fox], the) \n",
    "       - ([the, jumped], fox) \n",
    "       - ([fox, over], jumped)\n",
    "       - ([jumped, the], over) \n",
    "       - ...\n",
    "       \n",
    "       <img src=\"cbow.png\" width=\"50%\">\n",
    "       source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "   - **Skip Gram**: predict context based on target words\n",
    "   \n",
    "        <img src=\"skip_gram.png\" width=\"50%\">\n",
    "        source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a little longer and more detailed than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Only Michelle Branch save this album!!!!All gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A surprisingly good book, given its inherently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a wonderful, quiet and relaxing CD tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The lights that I received are absolutely not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  This is a little longer and more detailed than...\n",
       "1      1  Only Michelle Branch save this album!!!!All gu...\n",
       "2      2  A surprisingly good book, given its inherently...\n",
       "3      2  This is a wonderful, quiet and relaxing CD tha...\n",
       "4      1  The lights that I received are absolutely not ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], ['only', 'michelle', 'branch', 'save', 'this', 'album', 'all', 'guys', 'play', 'along', 'with', 'unenthusiastic', 'beat', 'even', 'karl']]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1 Train your word vector\n",
    "\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "\n",
    "# Load data\n",
    "data=pd.read_csv('amazon_review_large.csv')\n",
    "data.columns=['label','text']\n",
    "data.head()\n",
    "\n",
    "# tokenize each document into a list of unigrams\n",
    "# strip punctuations and leading/trailing spaces from unigrams\n",
    "# only unigrams with 2 or more characters are taken\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc.lower()) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in data[\"text\"]]\n",
    "print(sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 14:56:26,648 : INFO : collecting all words and their counts\n",
      "2021-12-15 14:56:26,649 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-12-15 14:56:26,753 : INFO : PROGRESS: at sentence #10000, processed 712099 words, keeping 36835 word types\n",
      "2021-12-15 14:56:26,859 : INFO : collected 55006 word types from a corpus of 1424497 raw words and 20000 sentences\n",
      "2021-12-15 14:56:26,860 : INFO : Creating a fresh vocabulary\n",
      "2021-12-15 14:56:26,910 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12138 unique words (22.0666836345126%% of original 55006, drops 42868)', 'datetime': '2021-12-15T14:56:26.910345', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-12-15 14:56:26,912 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1362451 word corpus (95.64435727137368%% of original 1424497, drops 62046)', 'datetime': '2021-12-15T14:56:26.912304', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-12-15 14:56:26,971 : INFO : deleting the raw counts dictionary of 55006 items\n",
      "2021-12-15 14:56:26,974 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2021-12-15 14:56:26,974 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1015978.4845063044 word corpus (74.6%% of prior 1362451)', 'datetime': '2021-12-15T14:56:26.974138', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2021-12-15 14:56:27,068 : INFO : estimated required memory for 12138 words and 200 dimensions: 25489800 bytes\n",
      "2021-12-15 14:56:27,069 : INFO : resetting layer weights\n",
      "2021-12-15 14:56:27,079 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-12-15T14:56:27.079882', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2021-12-15 14:56:27,080 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 12138 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-12-15T14:56:27.080865', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-12-15 14:56:27,577 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-12-15 14:56:27,578 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-15 14:56:27,584 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-15 14:56:27,586 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-15 14:56:27,587 : INFO : EPOCH - 1 : training on 1424497 raw words (1015999 effective words) took 0.5s, 2020476 effective words/s\n",
      "2021-12-15 14:56:28,067 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-12-15 14:56:28,072 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-15 14:56:28,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-15 14:56:28,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-15 14:56:28,077 : INFO : EPOCH - 2 : training on 1424497 raw words (1017083 effective words) took 0.5s, 2089165 effective words/s\n",
      "2021-12-15 14:56:28,569 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-12-15 14:56:28,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-15 14:56:28,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-15 14:56:28,578 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-15 14:56:28,579 : INFO : EPOCH - 3 : training on 1424497 raw words (1015958 effective words) took 0.5s, 2036022 effective words/s\n",
      "2021-12-15 14:56:29,064 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-12-15 14:56:29,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-15 14:56:29,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-15 14:56:29,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-15 14:56:29,075 : INFO : EPOCH - 4 : training on 1424497 raw words (1016131 effective words) took 0.5s, 2056789 effective words/s\n",
      "2021-12-15 14:56:29,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-12-15 14:56:29,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-12-15 14:56:29,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-12-15 14:56:29,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-12-15 14:56:29,567 : INFO : EPOCH - 5 : training on 1424497 raw words (1016041 effective words) took 0.5s, 2078559 effective words/s\n",
      "2021-12-15 14:56:29,568 : INFO : Word2Vec lifecycle event {'msg': 'training on 7122485 raw words (5081212 effective words) took 2.5s, 2044036 effective words/s', 'datetime': '2021-12-15T14:56:29.568102', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2021-12-15 14:56:29,568 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=12138, vector_size=200, alpha=0.025)', 'datetime': '2021-12-15T14:56:29.568102', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Train your own word vectors using gensim\n",
    "\n",
    "# gensim.models is the package for word2vec\n",
    "# check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# for detailed description\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# min_count: words with total frequency lower than this are ignored\n",
    "# size: the dimension of word vector\n",
    "# window: context window, i.e. the maximum distance \n",
    "#         between the current and predicted word \n",
    "#         within a sentence (i.e. the length of ngrams)\n",
    "# workers: # of parallel threads in training\n",
    "# for other parameters, check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "wv_model = word2vec.Word2Vec(sentences,vector_size=200,min_count=5, window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('metal', 0.7502920627593994),\n",
       " ('rock', 0.7445167303085327),\n",
       " ('beats', 0.7220752835273743),\n",
       " ('band', 0.7205601930618286),\n",
       " ('music', 0.718316912651062)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound' but not relevant to 'film'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rock', 0.8084051609039307),\n",
       " ('pop', 0.754722535610199),\n",
       " ('lyrics', 0.7281469106674194),\n",
       " ('dance', 0.7133382558822632),\n",
       " ('guitar', 0.7117939591407776)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'film':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9291705"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'city':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03990957"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word does not match with others in the list of ['sound', 'music', 'graphics', 'actor', 'book']:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'movie':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9398369 , -0.26979092, -0.32208118,  0.4484339 , -0.48991072,\n",
       "       -0.6396415 ,  1.1778913 ,  1.6906852 , -0.7643984 , -0.01410676,\n",
       "       -0.29183614,  0.21045597,  0.4607867 , -0.5672841 , -1.5674282 ,\n",
       "        0.34530285, -0.06660659, -1.359021  , -0.60741585, -1.2620932 ,\n",
       "        0.5776676 ,  0.91510093,  0.5721214 ,  0.76056534, -0.80147374,\n",
       "        1.1796416 , -0.60035974, -0.5805315 ,  1.4532441 , -0.44645214,\n",
       "       -0.01378889,  0.58523166,  0.6169707 ,  0.42398548, -1.6191436 ,\n",
       "        1.8783761 , -2.2982483 ,  0.22456075, -0.47139382,  0.5092724 ,\n",
       "        0.47057706, -0.6111662 ,  0.92382914, -0.0413982 ,  0.36029813,\n",
       "        0.7504785 , -0.06272805, -0.4524339 ,  0.5114244 ,  0.47090596,\n",
       "       -1.4466591 , -0.68480176, -0.07489015, -0.4293492 ,  0.5721016 ,\n",
       "       -1.260567  , -1.1860507 , -1.1670321 , -0.35003388,  1.5703514 ,\n",
       "        1.0453962 ,  0.5311113 ,  0.77049315, -0.03823433, -2.3480654 ,\n",
       "        0.11311954,  0.12703004, -0.2617225 , -1.4608952 ,  0.80091304,\n",
       "        0.36981645,  1.5017484 ,  0.96660185,  0.31489158,  0.8480155 ,\n",
       "       -1.4041963 ,  1.7999249 , -0.3790025 , -1.1146516 ,  0.75282747,\n",
       "       -0.25985274,  0.10113735, -0.91397417, -0.80263567,  0.8085866 ,\n",
       "       -0.06347846,  1.4598098 , -0.4727618 , -0.4522132 , -0.1149682 ,\n",
       "        0.15869457,  0.79870653,  1.0103196 ,  0.3635443 ,  0.309004  ,\n",
       "       -0.06185695, -1.9933977 , -0.76176435,  0.04827763,  2.5955665 ,\n",
       "        1.3254882 ,  0.39542323,  0.9863305 , -2.2328582 ,  1.5412441 ,\n",
       "        0.9459424 ,  0.19542557, -2.540604  ,  0.09183996,  1.4774997 ,\n",
       "        0.7541716 , -1.8872862 ,  0.7542227 ,  0.406525  ,  0.12071288,\n",
       "        0.3366592 ,  2.1036189 ,  0.1358601 ,  0.581235  , -1.0952692 ,\n",
       "       -0.6485097 ,  1.8048185 ,  0.27320904,  1.716583  ,  0.2604258 ,\n",
       "        0.36278293, -0.06860188,  0.43861675, -0.06010212,  0.39089498,\n",
       "        2.1885219 , -0.9511736 ,  1.0433178 , -0.09640965,  0.6338563 ,\n",
       "       -0.7814958 ,  0.46893865,  1.955495  ,  0.15701276, -0.34020674,\n",
       "       -0.30304256,  1.4708585 ,  0.15039253, -1.4895602 , -1.3546971 ,\n",
       "       -1.3373212 ,  0.1456852 ,  1.5451026 ,  0.74936056, -2.2802536 ,\n",
       "       -0.87803406, -0.1440147 ,  1.2661688 , -0.23842534,  1.7247937 ,\n",
       "        0.79562515,  0.5521524 ,  1.2399113 , -0.6760624 ,  0.7995702 ,\n",
       "        0.41974783, -0.26382264, -0.7755952 ,  2.4918928 , -0.13831435,\n",
       "        1.7696193 ,  1.5988231 ,  0.32590356, -0.09149057, -1.7461127 ,\n",
       "       -1.8177676 ,  0.7308001 , -0.8795615 , -0.83033746, -1.4312717 ,\n",
       "        0.4499308 ,  0.11215574,  1.7323154 ,  0.41104707,  0.31913975,\n",
       "       -0.28102395, -0.8969327 , -0.6480144 ,  1.3679082 ,  1.2536998 ,\n",
       "        0.90377563, -0.11701617, -0.14092645,  0.7263755 ,  0.44950998,\n",
       "       -0.00533588, -0.16495691,  0.26682007, -0.3677141 ,  1.0618993 ,\n",
       "        1.106728  , -0.33932742,  0.14780998, -0.7729986 ,  0.99038464],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word2vec model\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound'\")\n",
    "wv_model.wv.most_similar('sound', topn=5)\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound' but not relevant to 'film'\")\n",
    "wv_model.wv.most_similar(positive=['sound','music'], \\\n",
    "                         negative=['film'], topn=5)\n",
    "\n",
    "print(\"Similarity between 'movie' and 'film':\")\n",
    "wv_model.wv.similarity('movie','film') \n",
    "\n",
    "print(\"Similarity between 'movie' and 'city':\")\n",
    "wv_model.wv.similarity('movie','city') \n",
    "\n",
    "print(\"Word does not match with others in the list of \\\n",
    "['sound', 'music', 'graphics', 'actor', 'book']:\")\n",
    "wv_model.wv.doesnt_match([\"sound\", \"music\", \\\n",
    "                          \"graphics\", \"actor\", \"book\"])\n",
    "\n",
    "print(\"Word vector for 'movie':\")\n",
    "wv_model.wv['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Pretrained Word Vectors\n",
    "- Google published pre-trained 300-dimensional vectors for 3 million words and phrases that were trained on Google News dataset (about 100 billion words)(https://code.google.com/archive/p/word2vec/)\n",
    "- GloVe (Global Vectors for Word Representation): Pretained word vectors from different data sources provided by Standford https://nlp.stanford.edu/projects/glove/\n",
    "- FastText by Facebook https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md\n",
    "- Contextualized BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 14:38:45,682 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e7504588dab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GoogleNews-vectors-negative300.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m   1494\u001b[0m         \"\"\"\n\u001b[0;32m   1495\u001b[0m         \u001b[1;31m# from gensim.models.word2vec import load_word2vec_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             limit=limit, datatype=datatype)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading projection weights from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# throws for invalid file format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     fobj = _shortcut_open(\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[1;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'errors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'"
     ]
    }
   ],
   "source": [
    "# Exercise 1.2: Use pretrained word vectors\n",
    "\n",
    "# download the bin file for pretrained word vectors\n",
    "# from above links, e.g. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "# Warning: the bin file is very big (over 2G)\n",
    "# You need a powerful machine to load it\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.\\\n",
    "load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) \n",
    "\n",
    "model.wv.most_similar(positive=['women','king'], \\\n",
    "                      negative='man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. How to use word vectors in classification?\n",
    "\n",
    "`Convolutional Neural Network`\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2017/10/Depiction-of-the-multiple-channel-convolutional-neural-network-for-text.png\" width =\"100%\">\n",
    "\n",
    "`Recurrent Neural Network`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/graviraja/100-Days-of-NLP/master/assets/images/applications/sentiment/simple.gif\" width = \"90%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. More Advanced Transformer Model for Contextualized Embeddings\n",
    "\n",
    "\n",
    "<img src=\"https://sp-ao.shortpixel.ai/client/q_glossy,ret_img,w_780/https://conscient.ai/wp-content/uploads/2019/09/2-4.jpg\" width = \"90%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you and have a wonderful winter break!\n",
    "\n",
    "<img src=\"\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.kdnuggets.com/images/cartoon-machine-learning-vacation.jpg\" width='60%'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, welcome to join BIA-667 Deep Learning class in the Fall!\n",
    "\n",
    "<img src=\"https://www.qubole.com/wp-content/uploads/2018/08/1-400x387.png\" src=\"20%\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
