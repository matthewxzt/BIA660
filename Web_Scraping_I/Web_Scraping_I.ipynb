{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping</center>\n",
    "\n",
    "References: \n",
    " - https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    " - https://www.crummy.com/software/BeautifulSoup/bs4/doc/#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Different ways to access data on the web\n",
    " - Scrape HTML web pages \n",
    " - Download data file directly \n",
    "    * data files such as csv, txt\n",
    "    * pdf files\n",
    " - Access data through Application Programming Interface (API), e.g. The Movie DB, Twitter\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Basic structure of HTML ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HTML tages: <font color=\"green\">head</font>, <font color=\"green\">body</font>, <font color=\"green\">p</font>, <font color=\"green\">a</font>, <font color=\"green\">form</font>, <font color=\"green\">table </font>, ...\n",
    "* A tag may have properties. \n",
    "  * For example, tag <font color=\"green\">a</font> has property (or attribute) <font color=\"green\">href</font>, the target of the link\n",
    "  *  <font color=\"green\">class</font> and <font color=\"green\">id</font> are special properties used by html to control the style of each element through Cascading Style Sheets (CSS). <font color=\"green\">id</font> is the unique identifier of an element, and <font color=\"green\">class</font> is used to group elements for styling. \n",
    "      - An element can be associated with multiple classes. These classes are separated by space, e.g. `<h2 class=\"city main\">London</h2>`\n",
    "      - Very often, we can scrape by class (e.g. all `city` names) if CSS is used in the page\n",
    "      - For an illustrative example, check https://www.w3schools.com/html/tryit.asp?filename=tryhtml_classes_multiple\n",
    "* A tag can be referenced by its position in relation to each other \n",
    "  * **child** – a child is a tag inside another tag, e.g. the two <font color=\"green\">p</font> tags are children of the <font color=\"green\">div</font> tag.\n",
    "  * **parent** – a parent is the tag another tag is inside, e.g. the <font color=\"green\">html</font> tag is the parent of the <font color=\"green\">body</font> tag.\n",
    "  * **sibling** – a sibling is a tag that has the same parent as another tag, e.g. in the html example, the <font color=\"green\">head</font> and <font color=\"green\">body</font> tags are siblings, since they’re both inside <font color=\"green\">html</font>. Both <font color=\"green\">p</font> tags are siblings, since they’re both inside <font color=\"green\">body</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sample html source code (http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html).\n",
    "* A html document can be viewed as a tree structure\n",
    "\n",
    "<img src=\"html.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web page displayed:\n",
    "--------------------\n",
    "\n",
    "First paragraph.\n",
    "\n",
    "Second paragraph.\n",
    "\n",
    "**First outer paragraph.**\n",
    "\n",
    "**Second outer paragraph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Access HTML Elements: CSS Selector and XPATH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. CSS Selector \n",
    "- Most HTML pages are styled using CSS. \n",
    "- Identifying the various elements (e.g. `<h2 class=\"city main\">London</h2>`) on a page based on styles requires you to select the class (e.g. `city`) it falls into. \n",
    "- A CSS selector allows you to pick out the elements associated with CSS styles. \n",
    "- Advantages of Using CSS Selector\n",
    "  * It’s faster than XPath.\n",
    "  * It’s much easier to learn and implement.\n",
    "  * You have a high chance of finding your elements, since most CSS elements have explicit names or categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. XPath \n",
    "- XPath stands for XML Path -- a query language that helps identify elements from an XML document (HTML can be considered as XML too)\n",
    "- It uses expressions that navigate into an XML document in a way that can be traced from the start to the intended element—like forming a path from the start, e.g.\n",
    "  - `/`: root of the document\n",
    "  - `//`: start from anywhere of the document\n",
    "  - `@`: attribute\n",
    "  - `/html//p`: retrieve all `p` tags under `html` from the root\n",
    "  - `//p[@id=\"first\"]`: retrieve all `p` tags with an attribute `id` with value `first`\n",
    "  \n",
    "- Advantage:\n",
    "   - Flexible\n",
    "   - Support pattern match in element selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Examples of CSS Selector and XPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Goal|CSS Selector|XPath| \n",
    "|:-----|:-----|:-----|\n",
    "|All `P` elements|`p`|`//p` |  \n",
    "|All `p` descendants  under `body` | `body p`| `//body//p`|  \n",
    "|Element (e.g. `p`) By ID (e.g. `first`) |`p#first`|`//p[@id=’first’] ` |    \n",
    "|Element (e.g. `p`) By Class (e.g. `inner-text`)|`p.inner-text`|`//p[contains(@class,’inner-text’)]`|\n",
    "|Element (e.g. `p`) with Attribute (e.g. `name`)|`p[name=xyz]`|`//p[@name='xyz']`|    \n",
    "|All child elements under `p`|`p>*`|`//p/*`|          \n",
    "|First child of all P|`p>*:first-child`|`//p/*[0]`|                     \n",
    "|All P with an `a` child|Not possible|`//p[a]` |                      \n",
    "|Next element|`p + *`|`//p/following-sibling::*[0]`|\n",
    "|Previous element|Not possible|`//p/preceding-sibling::*[0]`|\n",
    "\n",
    "- For details of XPath, see https://www.w3schools.com/xml/xpath_syntax.asp\n",
    "- For details of CSS Selector, see https://www.w3schools.com/cssref/css_selectors.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Steps to scape HTML web pages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  1. Preparation\n",
    "     * Install modules <font color=\"green\">requests</font>, <font color=\"green\">BeautifulSoup4/scrapy/selenium/...</font>.\n",
    "        * **requests**: allow you to send HTTP/1.1 requests using Python. To install:\n",
    "           - Open terminal (Mac) or Anaconda Command Prompt (Windows)\n",
    "           - Issue: `pip install requests`\n",
    "        * **BeautifulSoup**: web page parsing library, to install, use: `pip install beautifulsoup4`\n",
    "     \n",
    "  2. Use <font color=\"green\">**requests**</font> library to retrive the source code\n",
    "  3. View **source code of the web page**: find out html elements that you will scrape\n",
    "      * **Firefox**: right click on the web page and select \"view page source\"\n",
    "      * **Safari**: please instruction here to see page source (http://ccm.net/faq/33026-safari-view-the-source-code-of-a-webpage)\n",
    "      * **Ineternet Explorer**: see instruction at https://www.computerhope.com/issues/ch000746.htm\n",
    "  4. Use libraries to parse the source code. Available libraries:\n",
    "      * <font color=\"green\">Beautifulsoup</font>: Simple, support CSS Selector, but not XPath\n",
    "      * <font color=\"green\">scrapy (https://scrapy.org/)</font>: Support CSS Selector and  XPath\n",
    "      * <font color=\"green\">Selenium</font>: Can scrape dynamic web pages\n",
    "      * <font color=\"green\">lxml</font>: another good library for web page scraping\n",
    "      * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scrape the sample html using BeautifulSoup ###\n",
    "- Kinds of Objects in BeautifulSoup\n",
    "  * <font color=\"green\">**Tag**</font>: an xml or HTML tag\n",
    "  * <font color=\"green\">**Name**</font>: every tag has a name\n",
    "  * <font color=\"green\">**Attributes**</font>: a tag may have any number of attributes. A tag is shown as a **dictionary** in the form of {attribute1_name:attribute1_value, attribute2_name:attribute2_value, ...}. If an attribute has multiple values, the value is stored as a list\n",
    "  * <font color=\"green\">**NavigableString**</font>: the text within a tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Retrieve HTML and Navigate the HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1.1 Import requests and beautifulsoup packages\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# import requests package\n",
    "import requests                   \n",
    "\n",
    "# import BeautifulSoup from package bs4 (i.e. beautifulsoup4)\n",
    "from bs4 import BeautifulSoup     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'\n",
      "<html>\n",
      "    <head>\n",
      "        <title>A simple example page</title>\n",
      "    </head>\n",
      "    <body>\n",
      "        <div>\n",
      "            <p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "            <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "        </div>\n",
      "        <p class=\"outer-text first-item\" id=\"second\">\n",
      "            <b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "        </p>\n",
      "        <p class=\"outer-text\">\n",
      "            <b>\n",
      "                Second outer paragraph.\n",
      "            </b>\n",
      "        </p>\n",
      "    </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.2 Get web page content\n",
    "\n",
    "# send a get request to the web page\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")    \n",
    "\n",
    "# status_code 200 indicates success. \n",
    "# a status code >200 indicates a failure\n",
    "if page.status_code==200:   \n",
    "    \n",
    "    # content property gives the content returned in bytes \n",
    "    print(page.content)  # text in bytes\n",
    "    print(page.text)     # text in unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basics of HTTP (Hypertext Transfer Protocol)**\n",
    "- HTTP is designed to enable communications between clients (e.g. browser) and servers (e.g. Apache web server).\n",
    "- A client submits an HTTP **request** to the server; then the server returns a **response** to the client. \n",
    "- Two commonly used methods for a request-response between a client and server:\n",
    "  - GET - Requests data from a specified resource\n",
    "  - POST - Submits data to be processed to a specified resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soup object:\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    First paragraph.\n",
      "   </p>\n",
      "   <p class=\"inner-text\">\n",
      "    Second paragraph.\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    First outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    Second outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.3 Parse web page content\n",
    "\n",
    "# Process the returned content using beautifulsoup module\n",
    "\n",
    "# initiate a beautifulsoup object using the html source and Python’s html.parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')  \n",
    "\n",
    "# soup object stands for the **root** \n",
    "# node of the html document tree\n",
    "\n",
    "print(\"Soup object:\")\n",
    "\n",
    "\n",
    "# print soup object nicely\n",
    "print(soup.prettify())                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\soup children nodes:\n",
      "<list_iterator object at 0x0000021A5542AA90>\n",
      "\n",
      "list of children of root:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# soup.children returns an iterator of all children nodes\n",
    "print(\"\\soup children nodes:\")\n",
    "soup_children=soup.children\n",
    "print(soup_children)\n",
    "\n",
    "# convert to list\n",
    "soup_children=list(soup.children)\n",
    "print(\"\\nlist of children of root:\")\n",
    "print(len(soup_children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                    \n",
    "# html is the only child of the root node\n",
    "html=soup_children[0]    \n",
    "\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many children under html?  5\n",
      "Child 0 is: \n",
      "\n",
      "\n",
      "Child 1 is: <head>\n",
      "<title>A simple example page</title>\n",
      "</head>\n",
      "\n",
      "Child 2 is: \n",
      "\n",
      "\n",
      "Child 3 is: <body>\n",
      "<div>\n",
      "<p class=\"inner-text first-item\" id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n",
      "</div>\n",
      "<p class=\"outer-text first-item\" id=\"second\">\n",
      "<b>\n",
      "                First outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "<p class=\"outer-text\">\n",
      "<b>\n",
      "                Second outer paragraph.\n",
      "            </b>\n",
      "</p>\n",
      "</body>\n",
      "\n",
      "Child 4 is: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.4 Get head and body tag\n",
    "\n",
    "html_children=list(html.children)\n",
    "\n",
    "print(\"how many children under html? \", len(html_children))\n",
    "\n",
    "for idx, child in enumerate(html_children):\n",
    "    print(\"Child {} is: {}\\n\".format(idx, child))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "head text:\n",
      "\n",
      "A simple example page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# head is the second child of html\n",
    "head=html_children[1]\n",
    "\n",
    "# extract all text inside head\n",
    "print(\"\\nhead text:\")\n",
    "print(head.get_text())\n",
    "\n",
    "# body is the fourth child of html\n",
    "body=html_children[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1.5 Continue the navigation through html document tree \n",
    "\n",
    "# Task 1. get div tag inside body. \n",
    "# div is the second child of body\n",
    "\n",
    "\n",
    "# Task 2: get the first p in div (2nd child of div)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data type:\n",
      "<class 'bs4.element.Tag'>\n",
      "\n",
      "tag name: \n",
      "p\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.6 Get details of a tag\n",
    "\n",
    "# get the first p tag in the div of body\n",
    "div=list(body.children)[1]\n",
    "p=list(div.children)[1]\n",
    "p\n",
    "\n",
    "# get the details of p tag\n",
    "# first, get the data type of p\n",
    "print(\"\\ndata type:\")\n",
    "print(type(p))\n",
    "# get tag name (property of p object)\n",
    "print (\"\\ntag name: \")     \n",
    "print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['inner-text', 'first-item'], 'id': 'first'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tag class: \n",
      "['inner-text', 'first-item']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n                First paragraph.\\n            '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tag object with attributes has a dictionary. \n",
    "# use <tag>.attrs to get the dictionary\n",
    "# each attribute name of the tag is a key\n",
    "\n",
    "# get all attributes \n",
    "p.attrs\n",
    "\n",
    "# get \"class\" attribute\n",
    "print (\"\\ntag class: \")\n",
    "print(p[\"class\"])\n",
    "\n",
    "# how to determine if 'id' is an attribute of p?\n",
    "\n",
    "# get text of p tag\n",
    "p.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Navigating the html document tree ###\n",
    " \n",
    "* Going down\n",
    "  * <font color=\"green\">**contents**</font>: get a tag's direct children as a **list**\n",
    "  * <font color=\"green\">**children**</font>: get a tag's direct chidren as an **iterator**\n",
    "  * <font color=\"green\">**descendants**</font>:  get an iterator for a tag's all descendants, including direct children, the children of its direct children, and so on\n",
    "* Going up\n",
    "  * <font color=\"green\">**parent**</font>: get a tag's parent\n",
    "  * <font color=\"green\">**parents**</font>: get an iterator for a tag's ancestors, from the parent to the very top of the document\n",
    "* Going sideways\n",
    "  * <font color=\"green\">**next_sibling**</font>: get a tag's next sibling\n",
    "  * <font color=\"green\">**previous_sibling**</font>: get a tag's previous sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get siblings of the first p tag\n",
      "['\\n', <p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>, '\\n']\n",
      "\n",
      "get the 2nd p tag\n",
      "<p class=\"inner-text\">\n",
      "                Second paragraph.\n",
      "            </p>\n"
     ]
    }
   ],
   "source": [
    " # Exercise 5.2.1  get siblings of p object\n",
    "print(\"\\nget siblings of the first p tag\")\n",
    "print(list(p.next_siblings))\n",
    "\n",
    "# get next p tag within the div\n",
    "# get the sibling next to the next sibling of p\n",
    "print(\"\\nget the 2nd p tag\")\n",
    "print(p.next_sibling.next_sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `find_all()`: Looks through a tag’s descendants and retrieves all descendants that match filters (https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all). A few examples:\n",
    "    * By tag name: `soup.find_all(\"title\")`\n",
    "    * By list of tag names: `soup.find_all([\"p\", \"title\"])`\n",
    "    * By attribtue: `soup.find_all(class_=\"inner-text\")`\n",
    "    * By attribtues: `data_soup.find_all(attrs={\"class\": \"inner-text\", \"id\":\"first\"})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>A simple example page</title>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>A simple example page</title>,\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>,\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all([\"b\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class is an attribute. \n",
    "# Since \"class\" is reserved, \n",
    "# use \"class_\" here\n",
    "soup.find_all(class_=\"inner-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(attrs={\"class\": \"inner-text\", \"id\":\"first\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.  Select tags into a list by CSS Selectors: select ###\n",
    "* CSS selectors used by CSS language to specify HTML tags to style\n",
    "* Originally, CSS selectors are patterns used to select elements for styling. \n",
    "* CSS selectors can be used to **choose html elements by node path**\n",
    "* List of patterns can be found at https://www.w3schools.com/cssref/css_selectors.asp\n",
    "* Some examples:\n",
    "  1. `div p` – finds all <font color=\"green\">p</font> tags inside a <font color=\"green\">div</font> tag.\n",
    "  2. `body p b` – finds all <font color=\"green\">b</font> tags inside a <font color=\"green\">p</font> tags within a <font color=\"green\">body</font> tag\n",
    "  3. `p.outer-text` – finds all <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text**.\n",
    "  4. `p#first` – finds all <font color=\"green\">p</font> tags with an <font color=\"green\">id</font> attribute of **first**\n",
    "  5. `p[class=outer-text]` – finds all <font color=\"green\">p</font> tags with a class attribute that is **exactly** \"outer-text\" (no other class). Note [ ] is the generic way to define a filter on any attribute. \".\" is just for \"class\" attribute.\n",
    "  6. `p[class~=outer-text]` – finds all <font color=\"green\">p</font> tags  with a class attribute that **contains** a value \"outer-text\" (it may contain other values too, equivalent to p.outer-text). \n",
    "  7. `body p.outer-text b` – finds any <font color=\"green\">b</font> tags within <font color=\"green\">p</font> tags with a <font color=\"green\">class</font> of **outer-text** inside of a <font color=\"green\">body</font> tag.\n",
    "  8. `div, p` – finds all <font color=\"green\">div</font> and <font color=\"green\">p</font> tags (without nesting relationships). Compare it with example #1!\n",
    "  9. `p.outer-text.first-item` – finds all <font color=\"green\">p</font> tags  with **both class attribute \"outer-text\" and \"first-item\"**.\n",
    "  10. What about finding all p with class \"outer-text\" but not class \"first-item\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.1: select p tags within div tags\n",
    "# Notice the space between div and p\n",
    "# This means p is a **descendant** of div \n",
    "# p is not necessarily a direct child of div\n",
    "soup.select(\"body p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3.2.: select b tags within p tags in the body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.3.: finds all p tags with a class of outer-text\n",
    "soup.select(\"p.outer-text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.4.: select p tags with id \"first\"\n",
    "soup.select(\"p#first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.5.:find p tag within body and\n",
    "# with a class attribute which is **exactly** \"outer-text\"\n",
    "\n",
    "# Note: this is the generic way to set  \n",
    "# a filter on any attribute\n",
    "\n",
    "soup.select(\"body p[class=outer-text]\")\n",
    "\n",
    "\n",
    "# compare the result with # Exercise 2.6.3.\n",
    "# how to select a line (i.e. tag \"a\") with a specific target, \n",
    "#   for example, http://www.stevens.edu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.6. find p tag with body \n",
    "# which has a class attribute **containing** a value \"out-text\"\n",
    "# Note the use of \"~\". \n",
    "\n",
    "soup.select(\"body p[class~=outer-text]\")\n",
    "\n",
    "# This is equivalent to soup.select(\"body p.outer-text\")\n",
    "# However, it's a generic way to set condition \n",
    "# on any type of attributes, not just \"class\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3.7. select b tags within \n",
    "# p tags which have a class outer-text and \n",
    "# are within the body tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div>\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>\n",
       " </div>,\n",
       " <p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>,\n",
       " <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>,\n",
       " <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>,\n",
       " <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.3.8. select all div and p tags \n",
    "# Compare the result with Exercise 2.6.1.\n",
    "# \",\" between tags means \"and/or\", \n",
    "# while \" \" (space) between tags means \"descendant\"\n",
    "\n",
    "soup.select(\"div, p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.3.9. select p tags \n",
    "# with two classes: outer-text and first-item\n",
    "soup.select(\"p.outer-text.first-item\")\n",
    "\n",
    "# what if another class, say \"xxx\" also required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 5.3.10 finding all p tags with class \"outer-text\" \n",
    "# but not class \"first-item\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.  Example: downloading weather forecast for the next week for New York City ###\n",
    "- Instruction:\n",
    "    1. Open web site http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU and inspect page source\n",
    "    2. Find \"Extended Forecast for\" in the source code\n",
    "    3. Extract div tags in this section using \"seven-day-forecast-body div ul li div.tombstone-container\"\n",
    "       * Notice that the div under \"Extended Forecast for\" is what we need\n",
    "       * Follow the path to weather forecast for each period\n",
    "       <img src='weather.png' width='100%'>\n",
    "    4. For each div tag, extract text in different p tags and represent the result as a tuple, e.g. (\"Today\", \"Mostly Sunny\", \"High: 75F\"). Save the 7-day forecast as a list and print the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ThisAfternoon', 'Slight ChanceShowers', 'High: 73 °F')\n",
      "('Tonight', 'Slight ChanceShowers', 'Low: 71 °F')\n",
      "('Wednesday', 'ChanceShowers', 'High: 76 °F')\n",
      "('WednesdayNight', 'ChanceShowers', 'Low: 75 °F')\n",
      "('Thursday', 'ShowersLikely', 'High: 74 °F')\n",
      "('ThursdayNight', 'ShowersLikely', 'Low: 64 °F')\n",
      "('Friday', 'ShowersLikely', 'High: 74 °F')\n",
      "('FridayNight', 'ChanceShowers thenPartly Cloudy', 'Low: 61 °F')\n",
      "('Saturday', 'Mostly Sunny', 'High: 74 °F')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2.7.1. downloading weather forecast for the next week for New York City \n",
    "\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.WXi6hlGQzIU\")    # send a get request to the web page\n",
    "rows=[]\n",
    "\n",
    "# status_code 200 indicates success. \n",
    "#a status code >200 indicates a failure \n",
    "if page.status_code==200:        \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # find a block with id='seven-day-forecast-body'\n",
    "    # follow the path down to the div for each period\n",
    "    divs=soup.select(\"div#seven-day-forecast-body \\\n",
    "    div ul li div.tombstone-container\")\n",
    "    #print len(divs)\n",
    "    #print divs\n",
    "    \n",
    "    for idx, div in enumerate(divs):\n",
    "        # for testing you can print idx, div\n",
    "        #print idx, div \n",
    "        \n",
    "        # initiate the variable for each period\n",
    "        title=None\n",
    "        desc=None\n",
    "        temp=None\n",
    "        \n",
    "        # get title\n",
    "        p_title=div.select(\"p.period-name\")\n",
    "        \n",
    "        # test if \"period-name\" indeed exists\n",
    "        # before you get the text\n",
    "        if p_title!=[]:\n",
    "            title=p_title[0].get_text()\n",
    "        \n",
    "        # get description\n",
    "        p_desc=div.select(\"p.short-desc\")\n",
    "        if p_desc!=[]:\n",
    "            desc=p_desc[0].get_text()\n",
    "        \n",
    "        # get temperature\n",
    "        p_temp=div.select(\"p.temp\")\n",
    "        if p_temp!=[]:\n",
    "            temp=p_temp[0].get_text()\n",
    "            \n",
    "        # add title, description, and temperature as a tuple into the list\n",
    "        rows.append((title, desc, temp))\n",
    "        print((title, desc, temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Scrapy and XPath\n",
    "- Another excellent library for web scraping\n",
    "- It supports both XPath and CSS selector\n",
    "- For details, check: https://docs.scrapy.org/en/latest/intro/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-09b341fbe58f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "from scrapy import Selector\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")    \n",
    "\n",
    "# status_code 200 indicates success. \n",
    "# a status code >200 indicates a failure\n",
    "if page.status_code==200:   \n",
    "    \n",
    "    sel = Selector(text = page.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8efd7361bc4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//body//p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# XPath selector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"body p\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# CSS selector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sel' is not defined"
     ]
    }
   ],
   "source": [
    "# soup.select(\"body p\")\n",
    "\n",
    "\n",
    "sel.xpath('//body//p').extract()  # XPath selector\n",
    "\n",
    "sel.css(\"body p\").extract()  # CSS selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b4cd9e531a8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# soup.select(\"body p[class~=outer-text]\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//p[contains(@class,\"outer-text\")]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"p.outer-text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sel' is not defined"
     ]
    }
   ],
   "source": [
    "# soup.select(\"p.outer-text\")\n",
    "# soup.select(\"body p[class~=outer-text]\")\n",
    "\n",
    "sel.xpath('//p[contains(@class,\"outer-text\")]').extract()\n",
    "\n",
    "sel.css(\"p.outer-text\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select(\"p#first\")\n",
    "\n",
    "sel.xpath('//p[@id=\"first\"]').extract()\n",
    "\n",
    "sel.css(\"p#first\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select(\"body p[class=outer-text]\")\n",
    "\n",
    "sel.xpath('//body//p[@class=\"outer-text\"]').extract()\n",
    "\n",
    "sel.css(\"body p[class=outer-text]\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.select(\"p.outer-text.first-item\")\n",
    "\n",
    "sel.xpath('//body//p[contains(@class,\"outer-text\") and \\\n",
    "                     contains(@class,\"first-item\")]').extract()\n",
    "\n",
    "sel.css(\"p.outer-text.first-item\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
